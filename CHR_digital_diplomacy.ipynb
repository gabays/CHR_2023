{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0nCdzCSYePV"
   },
   "source": [
    "# Transforming archives into data-driven analyses\n",
    "\n",
    "[CHR 2023](https://2023.computational-humanities-research.org/) Workshop\n",
    "\n",
    "Florian Cafiero, Jean-Luc Falcone and Simon Gabay\n",
    "\n",
    "<img alt=\"Licence Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88OBJ0nTFwDb"
   },
   "source": [
    "### Installations\n",
    "\n",
    "We will use two principal tools for information extraction:\n",
    "\n",
    "- To segment the pages, we are going to use [YALTAi](https://github.com/PonteIneptique/YALTAi) developped by Thibault Cl√©rice (more info: [arXiv.2207.11230](https://doi.org/10.48550/arXiv.2207.11230)).\n",
    "- To extract the text we use [Kraken](https://github.com/mittagessen/kraken) developed by Benjamin Kiessling (more info: [10.34894/Z9G2EX](https://doi.org/10.34894/Z9G2EX)).\n",
    "\n",
    "‚ö†Ô∏è YALTAi contains Kraken, no need to install it separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Wu9YL3djj4y"
   },
   "outputs": [],
   "source": [
    "!pip install kraken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5b6My2yBa9GX"
   },
   "source": [
    "## Image Segmentation\n",
    "\n",
    "We download [from the Digital Library of the UN](https://digitallibrary.un.org/record/196769) a resolution (`A_RES_45_212-EN`) on the _Protection of global climate for present and future generations of mankind_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p content\n",
    "!wget https://digitallibrary.un.org/record/196769/files/A_RES_45_212-EN.pdf  -P content\n",
    "# Change the name to simplify manipulations\n",
    "!mv content/A_RES_45_212-EN.pdf content/resolution.pdf\n",
    "# Convert pdf into images\n",
    "!pip install pypdfium2\n",
    "import pypdfium2 as pdfium\n",
    "#path to file\n",
    "pdf = pdfium.PdfDocument(\"content/resolution.pdf\")\n",
    "#number of pages\n",
    "n_pages = len(pdf)\n",
    "#turn into png\n",
    "for page_number in range(n_pages):\n",
    "    page = pdf.get_page(page_number)\n",
    "    pil_image = page.render(\n",
    "        scale=5, #1=72dpi, increase for a better resolution\n",
    "        rotation=0,\n",
    "        crop=(0, 0, 0, 0),\n",
    "    ).to_pil()\n",
    "    pil_image.save(f\"content/image_{page_number+1}.png\")\n",
    "#bit of cleaning\n",
    "!rm content/resolution.pdf\n",
    "!mkdir content/images\n",
    "!mv content/image*png content/images/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQNxmOVji8tT"
   },
   "source": [
    "Let's have a look at the this resolution now. Here is the first page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENttfHoLjU2S"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "\n",
    "image = mpimg.imread(\"content/images/image_1.png\")\n",
    "plt.figure(figsize=(30, 12), dpi=100)\n",
    "plt.imshow(image)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8-fF0KIiPsM"
   },
   "source": [
    "Some models are already available. We are going to use of model for historical French prints (16th c.-18th c.) trained at the University of Geneva by Maxime Humeau. This model is used for layout analyzing, using the controled vocabulary [SegmOnto](https://segmonto.github.io).\n",
    "\n",
    "SegmOnto is based on an as universal as possible modelling of a page.\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Historical Print</th>\n",
    "    <th>Medieval manuscript</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"images/btv1b86070385_f140_ann.jpg\" width=\"300px\"></td>\n",
    "    <td><img src=\"images/btv1b84259980_f29_ann.jpg\" width=\"340px\"></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Data have been prepared under the supervision of Ariane Pinche (CNRS) and Simon Gabay (UniGE) with [eScriptorium](https://ieeexplore.ieee.org/document/8893029), an open source web app to prepare data.\n",
    "\n",
    "<img src=\"images/escriptorium.png\" width=\"600px\">\n",
    "\n",
    "The University of Geneva is contributing via its own instance called [FoNDUE](https://www.unige.ch/lettres/humanites-numeriques/recherche/projets-de-la-chaire/fondue). The FoNDUE project aims at interfacing eScriptorium with HPC clusters using slurm (right) and not a single machine like other instances (left).\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/gabays/CHR_2023/main/images/Fondue.png\"  width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jsvJAq7lhxCO"
   },
   "outputs": [],
   "source": [
    "# Download the model\n",
    "!wget https://github.com/rayondemiel/Yolov8-Segmonto/releases/download/yolov8/remaining_goat_6779_best.pt -P content\n",
    "!mv content/remaining_goat_6779_best.pt content/seg_model.pt\n",
    "# Load the model\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"content/seg_model.pt\")\n",
    "# Use a GPU if you have one\n",
    "#model.to('cuda')\n",
    "model.info()\n",
    "# Fuse PyTorch Conv2d and BatchNorm2d layers. This improves inference time and therefore execution time.\n",
    "model.fuse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zysSkuiMlaWV"
   },
   "source": [
    "Let's use it now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nroZfyS7lbzX"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# Load the image\n",
    "img = \"content/images/image_1.png\"\n",
    "# Prediction\n",
    "results = model(img)\n",
    "# Plot the result\n",
    "for r in results:\n",
    "    im_array = r.plot(conf=True)  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    plt.figure(figsize=(30, 12), dpi=100)\n",
    "    plt.imshow(im)\n",
    "    plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHkL8ZedpUmj"
   },
   "source": [
    "## Optical character recognition\n",
    "\n",
    "I now need a Kraken model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hxLEkt_zRxF"
   },
   "outputs": [],
   "source": [
    "!cp UN_ft.mlmodel content\n",
    "!mv content/UN_ft.mlmodel content/htr_model.mlmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we segment\n",
    "\n",
    "‚ö†Ô∏è It takes a bit of time, approx. 1 minute / image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9VGzuXXq6Vg"
   },
   "outputs": [],
   "source": [
    "# Image Segmentation\n",
    "!yaltai kraken --device cpu -I \"content/images/*.png\" --suffix \".xml\" segment --yolo content/seg_model.pt\n",
    "print(\"pages have been segmented ü•≥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to correct the path of the image in the ALTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For mac\n",
    "!sed  -i'' -e \"s/content\\/images\\/image\\_/image_/g\" content/images/*.xml\n",
    "\n",
    "#For Linux\n",
    "#!sed -i \"s/content\\/images\\/image_/image_/g\" content/images/*.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we OCRise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUA9bfpaz-yk"
   },
   "outputs": [],
   "source": [
    "# HTR\n",
    "#!kraken --alto --suffix \".xml\" -I \"content/images/image*.xml\" -f alto ocr -m \"content/htr_model.mlmodel\"\n",
    "!kraken --suffix \".txt\" -I \"content/images/image*.xml\" -f alto ocr -m \"content/htr_model.mlmodel\"\n",
    "!mkdir -p content/data\n",
    "!mv content/images/*.xml data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For mac\n",
    "!sed  -i'' -e \"s/content\\/images\\/image\\_/image_/g\" content/images/*.xml\n",
    "#For Linux\n",
    "#!sed -i \"s/content\\/images\\/image_/image_/g\" content/images/*.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python scripts/alto2tei.py --config config.yml --version \"4.1.3\" --sourcedoc --body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
