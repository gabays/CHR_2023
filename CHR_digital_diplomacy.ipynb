{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gabays/CHR_2023/blob/main/CHR_digital_diplomacy.ipynb)\n",
        "\n",
        "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/gabays/CHR_2023/HEAD)\n",
        "\n",
        "\n",
        "# Transforming archives into data-driven analyses\n",
        "\n",
        "[CHR 2023](https://2023.computational-humanities-research.org/) Workshop\n",
        "\n",
        "Florian Cafiero, Jean-Luc Falcone and Simon Gabay\n",
        "\n",
        "<img alt=\"Licence Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" align=\"right\"/>"
      ],
      "metadata": {
        "id": "z0nCdzCSYePV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installations\n",
        "\n",
        "We will use two principal tools for information extraction:\n",
        "\n",
        "- To segment the pages, we are going to use [YALTAi](https://github.com/PonteIneptique/YALTAi) developped by Thibault Clérice (more info: [arXiv.2207.11230](https://doi.org/10.48550/arXiv.2207.11230)).\n",
        "- To extract the text we use [Kraken](https://github.com/mittagessen/kraken) developed by Benjamin Kiessling (more info: [10.34894/Z9G2EX](https://doi.org/10.34894/Z9G2EX)).\n",
        "\n",
        "⚠️ YALTAi contains Kraken, no need to install it separately"
      ],
      "metadata": {
        "id": "88OBJ0nTFwDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --root-user-action=ignore --upgrade setuptools\n",
        "print(\"setuptools\")\n",
        "!pip install --root-user-action=ignore --upgrade pip\n",
        "print(\"pip\")\n",
        "!pip install --root-user-action=ignore fastapi kaleido python-multipart uvicorn tabulate>=0.9 jedi>=0.16\n",
        "print(\"fastapi\")\n",
        "!pip install --root-user-action=ignore YALTAi torch==2.1.0"
      ],
      "metadata": {
        "id": "2Wu9YL3djj4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Segmentation\n",
        "\n",
        "We download [from the Digital Library of the UN](https://digitallibrary.un.org/record/196769) a resolution (`A_RES_45_212-EN`) on the _Protection of global climate for present and future generations of mankind_."
      ],
      "metadata": {
        "id": "5b6My2yBa9GX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://digitallibrary.un.org/record/196769/files/A_RES_45_212-EN.pdf?ln=fr\n",
        "# Change the name to simplify manipulations\n",
        "!mv A_RES_45_212-EN.pdf?ln=fr resolution.pdf\n",
        "# Convert pdf into images\n",
        "!pip install --root-user-action=ignore pdf2image\n",
        "!apt-get install poppler-utils\n",
        "from pdf2image import convert_from_path\n",
        "# Choose resolution\n",
        "dpi = 500 # dots per inch\n",
        "pdf_file = '/content/resolution.pdf'\n",
        "pages = convert_from_path(pdf_file ,dpi)\n",
        "# Convert images\n",
        "for i in range(len(pages)):\n",
        "   page = pages[i]\n",
        "   page.save('output_{}.jpg'.format(i), 'JPEG')\n",
        "# Save the result\n",
        "!mkdir /content/images\n",
        "!mv output_*.jpg images\n",
        "!rm /content/resolution.pdf"
      ],
      "metadata": {
        "id": "hR-lTrnKeD4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look at the this resolution now. Here is the first page:"
      ],
      "metadata": {
        "id": "OQNxmOVji8tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import image as mpimg\n",
        "\n",
        "image = mpimg.imread(\"/content/images/output_0.jpg\")\n",
        "plt.figure(figsize=(30, 12), dpi=100)\n",
        "plt.imshow(image)\n",
        "plt.gca().axes.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ENttfHoLjU2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some models are already available. We are going to use of model for historical French prints (16th c.-18th c.) trained at the University of Geneva by Maxime Humeau. This model is used for layout analyzing, using the controled vocabulary [SegmOnto](https://segmonto.github.io).\n",
        "\n",
        "SegmOnto is based on an as universal as possible modelling of a page.\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Historical Print</th>\n",
        "    <th>Medieval manuscript</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td><img src=\"https://raw.githubusercontent.com/gabays/CHR_2023/main/images/btv1b86070385_f140_ann.jpg\" height=\"300px\"></td>\n",
        "    <td><img src=\"https://raw.githubusercontent.com/gabays/CHR_2023/main/images/btv1b84259980_f29_ann.jpg\" height=\"300px\"></td>\n",
        "\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Data have been prepared under the supervision of Ariane Pinche (CNRS) and Simon Gabay (UniGE) with [eScriptorium](https://ieeexplore.ieee.org/document/8893029), an open source web app to prepare data.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/gabays/CHR_2023/main/images/escriptorium.png\" height=\"300px\">\n",
        "\n",
        "The University of Geneva is contributing via its own instance called [FoNDUE](https://www.unige.ch/lettres/humanites-numeriques/recherche/projets-de-la-chaire/fondue). The FoNDUE project aims at interfacing eScriptorium with HPC clusters using slurm (right) and not a single machine like other instances (left).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/gabays/CHR_2023/main/images/Fondue.png\" height=\"250px\">\n"
      ],
      "metadata": {
        "id": "j8-fF0KIiPsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the model\n",
        "!wget https://github.com/rayondemiel/Yolov8-Segmonto/releases/download/yolov8/remaining_goat_6779_best.pt\n",
        "!mv remaining_goat_6779_best.pt seg_model.pt\n",
        "# Load the model\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(\"/content/seg_model.pt\")\n",
        "# Use GPU\n",
        "model.to('cuda')\n",
        "model.info()\n",
        "# Fuse PyTorch Conv2d and BatchNorm2d layers. This improves inference time and therefore execution time.\n",
        "model.fuse()"
      ],
      "metadata": {
        "id": "jsvJAq7lhxCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use it now!"
      ],
      "metadata": {
        "id": "zysSkuiMlaWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "# Load the image\n",
        "img = \"/content/images/output_0.jpg\"\n",
        "# Prediction\n",
        "results = model(img)\n",
        "# Plot the result\n",
        "for r in results:\n",
        "    im_array = r.plot(conf=True)  # plot a BGR numpy array of predictions\n",
        "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
        "    plt.figure(figsize=(30, 12), dpi=100)\n",
        "    plt.imshow(im)\n",
        "    plt.gca().axes.get_yaxis().set_visible(False)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "nroZfyS7lbzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optical character recognition\n",
        "\n",
        "I now need a Kraken model:"
      ],
      "metadata": {
        "id": "sHkL8ZedpUmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/gabays/CHR_2023/raw/main/19thcenturyprint.mlmodel\n",
        "!mv /content/19thcenturyprint.mlmodel /content/htr_model.mlmodel"
      ],
      "metadata": {
        "id": "-hxLEkt_zRxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Segmentation\n",
        "!yaltai kraken --device cuda:0 -I \"/content/images/output_0.jpg\" --suffix \".xml\" segment --yolo /content/seg_model.pt\n",
        "!mkdir segmented\n",
        "!mv /content/images/*.xml segmented\n",
        "# HTR\n",
        "!kraken --alto --suffix \".xml\" -I \"/content/segmented/*.xml\" -f alto ocr -m \"/content/htr_model.mlmodel\""
      ],
      "metadata": {
        "id": "x9VGzuXXq6Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nUA9bfpaz-yk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}